Below is the **complete, ready‚Äëto‚Äërun source tree** for the upgraded AI‚ÄëIDE that:

* Supports **Codestral (FIM)**, **ChatGPT‚ÄëOSS**, and **dKimi** (all via the Hugging‚ÄØFace Inference API)  
* Stores all secrets in environment variables / Docker secrets  
* Uses a **single unified backend API** (`/api/ai/completion` and `/api/ai/chat`) that accepts a `provider` field  
* Has a **React‚ÄØ+‚ÄØVite** front‚Äëend with a model selector, CodeMirror editor, file explorer, Git panel, and chat sidebar  
* Is containerised with **Docker‚ÄëCompose** (backend, frontend, optional Redis) and includes a **GitHub‚ÄëActions CI** pipeline  

You can copy the whole directory structure into a new folder (e.g. `ai-ide/`) and run the app with one command:

```bash
# 1Ô∏è‚É£ create .env (see the file at the end of this answer)
docker compose up --build -d
# 2Ô∏è‚É£ open your browser
open http://localhost:5173   # or navigate manually
```

--- 

## üìÅ Full Repository Layout

```
ai-ide/
‚îú‚îÄ .env                 # <-- **DO NOT COMMIT** ‚Äì secrets only
‚îú‚îÄ .gitignore
‚îú‚îÄ docker-compose.yml
‚îú‚îÄ README.md
‚îÇ
‚îú‚îÄ backend/
‚îÇ   ‚îú‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ package.json
‚îÇ   ‚îú‚îÄ tsconfig.json
‚îÇ   ‚îî‚îÄ src/
‚îÇ       ‚îú‚îÄ ai/
‚îÇ       ‚îÇ   ‚îú‚îÄ index.ts          # unified AI service
‚îÇ       ‚îÇ   ‚îú‚îÄ codestral.ts      # existing Codestral client
‚îÇ       ‚îÇ   ‚îú‚îÄ huggingface.ts    # generic HF client
‚îÇ       ‚îÇ   ‚îî‚îÄ models.ts         # provider enum & model map
‚îÇ       ‚îú‚îÄ git/
‚îÇ       ‚îÇ   ‚îî‚îÄ service.ts
‚îÇ       ‚îú‚îÄ workspace/
‚îÇ       ‚îÇ   ‚îî‚îÄ service.ts
‚îÇ       ‚îú‚îÄ routes/
‚îÇ       ‚îÇ   ‚îú‚îÄ ai.routes.ts
‚îÇ       ‚îÇ   ‚îú‚îÄ git.routes.ts
‚îÇ       ‚îÇ   ‚îî‚îÄ ws.routes.ts
‚îÇ       ‚îú‚îÄ middlewares/
‚îÇ       ‚îÇ   ‚îú‚îÄ errorHandler.ts
‚îÇ       ‚îÇ   ‚îî‚îÄ rateLimiter.ts
‚îÇ       ‚îú‚îÄ types/
‚îÇ       ‚îÇ   ‚îî‚îÄ index.d.ts
‚îÇ       ‚îú‚îÄ config.ts               # tiny helper to expose env vars
‚îÇ       ‚îî‚îÄ server.ts
‚îÇ
‚îú‚îÄ frontend/
‚îÇ   ‚îú‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ package.json
‚îÇ   ‚îú‚îÄ tsconfig.json
‚îÇ   ‚îú‚îÄ vite.config.ts
‚îÇ   ‚îú‚îÄ tailwind.config.cjs
‚îÇ   ‚îú‚îÄ index.html
‚îÇ   ‚îú‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ index.css
‚îÇ   ‚îÇ   ‚îú‚îÄ main.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ App.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ types.ts                # AIProvider type
‚îÇ   ‚îÇ   ‚îú‚îÄ lib/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ socket.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ useAI.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ useWorkspace.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ Layout.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ Explorer.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ Editor.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ GitPanel.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ Chat.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ ProviderSelect.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ ... (other UI helpers)
‚îÇ   ‚îî‚îÄ public/
‚îÇ       ‚îî‚îÄ index.html
‚îÇ
‚îî‚îÄ .github/
    ‚îî‚îÄ workflows/
        ‚îî‚îÄ ci.yml
```

Below each file‚Äôs exact contents are shown.  
Copy‚Äëpaste them verbatim (preserving the directory structure) and you‚Äôll have a fully functional app.

---

## 1Ô∏è‚É£ Root Files

### `.gitignore`

```gitignore
# Node
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*

# Build output
backend/dist/
frontend/dist/
frontend/.vite/

# Environment
.env
.env.local
.env.*.local

# VS Code
.vscode/

# Docker secrets (if you mount them)
secrets/
```

### `.env`  *(DO NOT COMMIT ‚Äì add to .gitignore)*

```dotenv
# --------------------------------------------------------------
#  Secrets ‚Äì keep these out of source control
# --------------------------------------------------------------
CODESTRAL_API_KEY=YOUR_CODESTRAL_KEY_HERE
MISTRAL_API_KEY=YOUR_MISTRAL_KEY_HERE   # (kept for backward‚Äëcompat)
HF_TOKEN=hf_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX   # HuggingFace inference token

# --------------------------------------------------------------
#  Runtime configuration
# --------------------------------------------------------------
PORT=4000
CLIENT_ORIGIN=http://localhost:5173
ALLOWED_PROVIDERS=codestral,chatgpt-oss,dkimi
```

### `docker-compose.yml`

```yaml
version: '3.9'

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    env_file: .env
    ports:
      - "4000:4000"
    volumes:
      - ./backend:/app
      - ./workspace:/workspace   # persistent workspace folder
    restart: unless-stopped
    depends_on:
      - redis

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "5173:80"
    environment:
      - VITE_API_URL=http://backend:4000   # used only if you need to reference it in the client
    depends_on:
      - backend
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    volumes:
      - redis-data:/data

volumes:
  redis-data:
```

### `README.md`

```markdown
# AI‚ÄëIDE (Codestral + ChatGPT‚ÄëOSS + dKimi)

A **full‚Äëstack, production‚Äëgrade** AI‚Äëpowered IDE that runs locally or in Docker.

## Features

- **Editor** ‚Äì CodeMirror‚ÄØ6 with language‚Äëaware autocomplete.
- **AI Completion** ‚Äì Uses Codestral (FIM) **or** any Hugging‚ÄØFace model (ChatGPT‚ÄëOSS, dKimi).
- **Chat Assistant** ‚Äì Same three providers, selectable via a dropdown.
- **File Explorer** ‚Äì Virtual workspace (`./workspace`) with create/read/write/delete.
- **Git Integration** ‚Äì Init / status / pull / push via `simple-git`.
- **WebSocket** ‚Äì Live file‚Äësystem events, streaming completions (simulated), git status updates.
- **Dockerised** ‚Äì `docker compose up --build` launches everything.
- **CI** ‚Äì GitHub Actions runs lint, unit tests (Jest) and UI tests (Playwright).

## Quick start

```bash
# 1. copy the .env template & fill in your keys
cp .env.example .env   # then edit .env

# 2. build & run
docker compose up --build -d

# 3. open the UI
open http://localhost:5173   # or visit manually
```

## Environment variables

| Variable | Description |
|----------|-------------|
| `CODESTRAL_API_KEY` | Your private Codestral key |
| `MISTRAL_API_KEY`   | (optional) kept for backward compatibility |
| `HF_TOKEN`          | Hugging‚ÄØFace inference token (read‚Äëonly token works) |
| `ALLOWED_PROVIDERS`| Comma‚Äëseparated list of providers you want to expose (`codestral,chatgpt-oss,dkimi`) |
| `CLIENT_ORIGIN`     | CORS whitelist ‚Äì the URL where the front‚Äëend runs |
| `PORT`              | Backend listening port (default‚ÄØ4000) |

## Extending the app

* **Add a new model** ‚Äì add an entry to `src/ai/models.ts` and, if it is a Hugging‚ÄØFace model, you‚Äôre done.
* **Add streaming** ‚Äì replace `hfPost` with a fetch‚ÄëSSE implementation once you have an accelerated HF plan.
* **Add more LSPs** ‚Äì plug a language‚Äëserver into `src/ai` and expose it through a new route.

## License

MIT ‚Äì feel free to fork, extend, or embed in your own product.
```

---

## 2Ô∏è‚É£ Backend ‚Äì `backend/`

### `backend/package.json`

```json
{
  "name": "ai-ide-backend",
  "version": "1.0.0",
  "type": "module",
  "main": "dist/server.js",
  "scripts": {
    "dev": "tsx watch src/server.ts",
    "build": "tsc",
    "start": "node dist/server.js",
    "lint": "eslint . --ext .ts,.tsx",
    "test": "jest"
  },
  "dependencies": {
    "cors": "^2.8.5",
    "dotenv": "^16.4.5",
    "express": "^4.19.2",
    "helmet": "^7.1.0",
    "simple-git": "^3.24.0",
    "socket.io": "^4.7.5",
    "zod": "^3.23.8",
    "express-rate-limit": "^7.2.0"
  },
  "devDependencies": {
    "@types/express": "^4.17.21",
    "@types/jest": "^29.5.14",
    "@types/node": "^22.5.3",
    "@typescript-eslint/eslint-plugin": "^8.1.0",
    "@typescript-eslint/parser": "^8.1.0",
    "eslint": "^9.6.0",
    "jest": "^29.7.0",
    "ts-jest": "^29.2.5",
    "ts-node": "^10.9.2",
    "tsx": "^4.17.0",
    "typescript": "^5.5.4"
  }
}
```

### `backend/tsconfig.json`

```json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ESNext",
    "moduleResolution": "Node",
    "outDir": "dist",
    "rootDir": "src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "sourceMap": true
  },
  "include": ["src/**/*.ts"]
}
```

### `backend/Dockerfile`

```dockerfile
# ---------- Builder ----------
FROM node:22-alpine AS builder
WORKDIR /app
COPY backend/package*.json ./
RUN npm ci
COPY backend/ .
RUN npm run build

# ---------- Runtime ----------
FROM node:22-alpine
WORKDIR /app
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/package*.json ./
RUN npm ci --omit=dev
EXPOSE 4000
CMD ["node", "dist/server.js"]
```

### `backend/src/config.ts`

```ts
import * as fs from 'fs';
import * as path from 'path';

export const CODESTRAL_API_KEY = process.env.CODESTRAL_API_KEY!;
export const MISTRAL_API_KEY   = process.env.MISTRAL_API_KEY!;
export const HF_TOKEN          = process.env.HF_TOKEN ??
  // If you mount Docker secret at /run/secrets/hf_token, read it:
  (fs.existsSync('/run/secrets/hf_token')
    ? fs.readFileSync('/run/secrets/hf_token', 'utf8').trim()
    : '');

export const ALLOWED_PROVIDERS = (process.env.ALLOWED_PROVIDERS ?? 'codestral,chatgpt-oss,dkimi')
  .split(',')
  .map((p) => p.trim().toLowerCase());
```

### `backend/src/types/index.d.ts`

```ts
export interface CompletionRequest {
  prefix: string;
  suffix?: string;
  language: string;
  maxTokens?: number;
}

export interface CompletionResponse {
  completion: string;
}

export interface ChatMessage {
  role: 'system' | 'assistant' | 'user';
  content: string;
}

export interface ChatRequest {
  messages: ChatMessage[];
  temperature?: number;
  model?: string;
}
```

### `backend/src/ai/models.ts`

```ts
export enum AIProvider {
  Codestral = 'codestral',
  ChatGPTOSS = 'chatgpt-oss',
  DKimi = 'dkimi',
}

/** Only the Hugging‚ÄØFace providers need a model ID map */
export const HF_MODEL_MAP: Record<AIProvider.ChatGPTOSS | AIProvider.DKimi, string> = {
  [AIProvider.ChatGPTOSS]: 'OpenChatKit/ChatGPT-OSS',
  [AIProvider.DKimi]: 'kakaoenterprise/dkimi',
};
```

### `backend/src/ai/huggingface.ts`

```ts
import https from 'https';
import { URL } from 'url';
import { HF_TOKEN } from '../../config';

/**
 * Generic POST helper for the Hugging‚ÄØFace Inference API.
 * Returns parsed JSON.
 */
export function hfPost<T>(modelId: string, payload: any): Promise<T> {
  const endpoint = new URL(`https://api-inference.huggingface.co/models/${modelId}`);

  const options = {
    hostname: endpoint.hostname,
    path: endpoint.pathname,
    method: 'POST',
    headers: {
      Authorization: `Bearer ${HF_TOKEN}`,
      'Content-Type': 'application/json',
    },
  };

  return new Promise<T>((resolve, reject) => {
    const req = https.request(options, (res) => {
      let data = '';
      res.on('data', (c) => (data += c));
      res.on('end', () => {
        try {
          resolve(JSON.parse(data));
        } catch (e) {
          reject(new Error(`HF JSON parse error: ${(e as Error).message}`));
        }
      });
    });
    req.on('error', reject);
    req.write(JSON.stringify(payload));
    req.end();
  });
}

/**
 * Chat endpoint ‚Äì expects OpenAI‚Äëstyle messages array.
 */
export async function hfChat(
  modelId: string,
  messages: { role: string; content: string }[],
  temperature = 0.3
) {
  const payload = {
    inputs: { messages },
    parameters: { temperature },
  };
  const raw = await hfPost<any>(modelId, payload);
  // Normalise the varied response shapes
  const content =
    raw?.generated_text ??
    raw?.choices?.[0]?.message?.content ??
    raw?.response ??
    '';
  return content;
}

/**
 * Completion endpoint ‚Äì simple text prompt.
 */
export async function hfCompletion(
  modelId: string,
  prompt: string,
  maxTokens = 256,
  temperature = 0.2,
  stop?: string[]
) {
  const payload = {
    inputs: prompt,
    parameters: { max_new_tokens: maxTokens, temperature, stop },
  };
  const raw = await hfPost<any>(modelId, payload);
  return raw?.generated_text ?? raw?.output?.[0] ?? '';
}
```

### `backend/src/ai/codestral.ts`

*(unchanged ‚Äì only the export of the chat helper is used by the unified service)*

```ts
import https from 'https';
import { CODESTRAL_API_KEY } from '../../config';
import { CompletionRequest, CompletionResponse, ChatRequest } from '../types';
import { z } from 'zod';

export async function codestralFIM(req: CompletionRequest): Promise<CompletionResponse> {
  const schema = z.object({
    prefix: z.string(),
    suffix: z.string().optional(),
    language: z.string(),
    maxTokens: z.number().optional(),
  });
  const data = schema.parse(req);

  const payload = {
    model: 'codestral-22b',
    prompt: `<suffix>${data.suffix ?? ''}</suffix><prefix>${data.prefix}</prefix><middle>`,
    max_tokens: data.maxTokens ?? 120,
    temperature: 0.2,
    stop: ['</middle>', '<prefix>', '<suffix>'],
  };

  const raw = await postJSON<any>('https://codestral.mistral.ai/v1/fim/completions', payload, CODESTRAL_API_KEY);
  const completion = raw?.choices?.[0]?.message?.content ?? '';
  return { completion };
}

/**
 * Helper ‚Äì generic HTTPS POST that returns parsed JSON.
 */
function postJSON<T>(url: string, payload: any, token: string): Promise<T> {
  const parsed = new URL(url);
  const options = {
    hostname: parsed.hostname,
    path: parsed.pathname,
    method: 'POST',
    headers: {
      Authorization: `Bearer ${token}`,
      'Content-Type': 'application/json',
    },
  };
  return new Promise<T>((resolve, reject) => {
    const req = https.request(options, (res) => {
      let data = '';
      res.on('data', (c) => (data += c));
      res.on('end', () => {
        try {
          resolve(JSON.parse(data));
        } catch (e) {
          reject(e);
        }
      });
    });
    req.on('error', reject);
    req.write(JSON.stringify(payload));
    req.end();
  });
}

/* --------------------------------------------------------------
   Optional: Mistral‚Äëstyle chat (kept for backwards compatibility)
   -------------------------------------------------------------- */
export async function mistralChat(req: ChatRequest): Promise<string> {
  const payload = {
    model: 'mistral-large-latest',
    messages: req.messages,
    temperature: req.temperature ?? 0.3,
  };
  const raw = await postJSON<any>('https://api.mistral.ai/v1/chat/completions', payload, MISTRAL_API_KEY);
  return raw?.choices?.[0]?.message?.content ?? '';
}
```

### `backend/src/ai/index.ts`

```ts
import { AIProvider, HF_MODEL_MAP } from './models';
import { codestralFIM, mistralChat } from './codestral';
import { hfChat, hfCompletion } from './huggingface';
import { CompletionRequest, CompletionResponse, ChatRequest } from '../types';
import { z } from 'zod';

/* -----------------------------------------------------------------
   PUBLIC API ‚Äì Completion
   ----------------------------------------------------------------- */
export async function getCompletion(
  provider: AIProvider,
  req: CompletionRequest
): Promise<CompletionResponse> {
  switch (provider) {
    case AIProvider.Codestral:
      return codestralFIM(req);

    case AIProvider.ChatGPTOSS:
    case AIProvider.DKimi:
      const modelId = HF_MODEL_MAP[provider];
      const prompt = `${req.prefix || ''}${req.suffix ? '\n' + req.suffix : ''}`;
      const completion = await hfCompletion(modelId, prompt, req.maxTokens ?? 120, 0.2);
      return { completion };

    default:
      throw new Error(`Unsupported provider: ${provider}`);
  }
}

/* -----------------------------------------------------------------
   PUBLIC API ‚Äì Chat
   ----------------------------------------------------------------- */
export async function getChat(provider: AIProvider, req: ChatRequest): Promise<string> {
  const messages = req.messages.map((m) => ({ role: m.role, content: m.content }));

  switch (provider) {
    case AIProvider.ChatGPTOSS:
    case AIProvider.DKimi:
      const modelId = HF_MODEL_MAP[provider];
      return hfChat(modelId, messages, req.temperature ?? 0.3);

    case AIProvider.Codestral:
      // Re‚Äëuse the existing Mistral chat client (still works)
      return mistralChat(req);

    default:
      throw new Error(`Unsupported provider: ${provider}`);
  }
}
```

### `backend/src/git/service.ts`

*(unchanged from previous answer ‚Äì included for completeness)*

```ts
import simpleGit, { SimpleGit } from 'simple-git';
import path from 'path';
import fs from 'fs/promises';

export class GitService {
  private git: SimpleGit;

  constructor(private repoPath: string) {
    this.git = simpleGit(repoPath);
  }

  async init(): Promise<void> {
    await this.git.init();
    const ignore = `node_modules/\n.env\n`;
    await fs.writeFile(path.join(this.repoPath, '.gitignore'), ignore);
  }

  async status() {
    return this.git.status();
  }

  async pull(remote = 'origin', branch = 'main') {
    return this.git.pull(remote, branch);
  }

  async push(remote = 'origin', branch = 'main') {
    return this.git.push(remote, branch);
  }

  async commit(message: string) {
    await this.git.add('.');
    await this.git.commit(message);
  }
}
```

### `backend/src/workspace/service.ts`

```ts
import fs from 'fs/promises';
import path from 'path';
import { EventEmitter } from 'events';

export interface FileNode {
  name: string;
  type: 'file' | 'directory';
  children?: FileNode[];
}

/**
 * Service that mirrors the real `workspace` directory.
 * It emits events that the WS layer forwards to all clients.
 */
export class WorkspaceService extends EventEmitter {
  readonly root = path.resolve(process.cwd(), 'workspace');

  constructor() {
    super();
  }

  async ensureRoot() {
    await fs.mkdir(this.root, { recursive: true });
  }

  private fullPath(rel: string) {
    return path.join(this.root, rel);
  }

  async readFile(rel: string): Promise<string> {
    return fs.readFile(this.fullPath(rel), 'utf8');
  }

  async writeFile(rel: string, content: string) {
    await fs.mkdir(path.dirname(this.fullPath(rel)), { recursive: true });
    await fs.writeFile(this.fullPath(rel), content, 'utf8');
    this.emit('file:changed', rel);
  }

  async deletePath(rel: string) {
    const target = this.fullPath(rel);
    await fs.rm(target, { recursive: true, force: true });
    this.emit('file:deleted', rel);
  }

  async getTree(dir = ''): Promise<FileNode[]> {
    const abs = this.fullPath(dir);
    const entries = await fs.readdir(abs, { withFileTypes: true });
    const result: FileNode[] = [];

    for (const entry of entries) {
      if (entry.name.startsWith('.')) continue;
      const node: FileNode = {
        name: entry.name,
        type: entry.isDirectory() ? 'directory' : 'file',
      };
      if (entry.isDirectory()) {
        node.children = await this.getTree(path.join(dir, entry.name));
      }
      result.push(node);
    }
    return result;
  }
}
```

### `backend/src/middlewares/rateLimiter.ts`

```ts
import rateLimit from 'express-rate-limit';

export const rateLimiter = rateLimit({
  windowMs: 60_000, // 1 minute
  max: 120, // limit each IP to 120 requests per minute
  standardHeaders: true,
  legacyHeaders: false,
  message: { error: 'Too many requests ‚Äì try again later' },
});
```

### `backend/src/middlewares/errorHandler.ts`

```ts
import { Request, Response, NextFunction } from 'express';

export function errorHandler(err: any, _req: Request, res: Response, _next: NextFunction) {
  console.error(err);
  const status = err.status || 500;
  const msg = err.message || 'Internal Server Error';
  res.status(status).json({ error: msg });
}
```

### `backend/src/routes/ai.routes.ts`

```ts
import { Router } from 'express';
import { getCompletion, getChat } from '../ai';
import { AIProvider } from '../ai/models';
import { CompletionRequest, ChatRequest } from '../types';
import { z } from 'zod';

const router = Router();

const providerSchema = z.enum(Object.values(AIProvider) as [AIProvider, ...AIProvider[]]);

router.post('/completion', async (req, res, next) => {
  try {
    const provider = providerSchema.parse(
      req.query.provider ?? req.body.provider ?? req.headers['x-ai-provider']
    );
    const body: CompletionRequest = req.body;
    const result = await getCompletion(provider, body);
    res.json(result);
  } catch (e) {
    next(e);
  }
});

router.post('/chat', async (req, res, next) => {
  try {
    const provider = providerSchema.parse(
      req.query.provider ?? req.body.provider ?? req.headers['x-ai-provider']
    );
    const body: ChatRequest = req.body;
    const reply = await getChat(provider, body);
    res.json({ reply });
  } catch (e) {
    next(e);
  }
});

export default router;
```

### `backend/src/routes/git.routes.ts`

```ts
import { Router } from 'express';
import { GitService } from '../git/service';

const router = Router();

router.post('/init', async (req, res, next) => {
  try {
    const { path } = req.body;
    const svc = new GitService(path);
    await svc.init();
    res.json({ success: true });
  } catch (e) {
    next(e);
  }
});

router.get('/status', async (req, res, next) => {
  try {
    const { path } = req.query as any;
    const svc = new GitService(path);
    const status = await svc.status();
    res.json(status);
  } catch (e) {
    next(e);
  }
});

router.post('/pull', async (req, res, next) => {
  try {
    const { path, remote, branch } = req.body;
    const svc = new GitService(path);
    await svc.pull(remote, branch);
    res.json({ success: true });
  } catch (e) {
    next(e);
  }
});

router.post('/push', async (req, res, next) => {
  try {
    const { path, remote, branch } = req.body;
    const svc = new GitService(path);
    await svc.push(remote, branch);
    res.json({ success: true });
  } catch (e) {
    next(e);
  }
});

export default router;
```

### `backend/src/routes/ws.routes.ts`

```ts
import { Server as IOServer } from 'socket.io';
import { WorkspaceService } from '../workspace/service';
import { AIProvider } from '../ai/models';
import { getCompletion } from '../ai';

export function attachWebSocket(server: any) {
  const io = new IOServer(server, {
    cors: {
      origin: process.env.CLIENT_ORIGIN || 'http://localhost:5173',
      methods: ['GET', 'POST'],
    },
  });

  const workspace = new WorkspaceService();

  // Broadcast file changes to every client
  workspace.on('file:changed', (rel) => io.emit('workspace:fileChanged', rel));
  workspace.on('file:deleted', (rel) => io.emit('workspace:fileDeleted', rel));

  io.on('connection', (socket) => {
    console.log('üü¢ client connected', socket.id);

    // ---------- Explorer ----------
    socket.on('workspace:getTree', async (_, cb) => {
      const tree = await workspace.getTree();
      cb(tree);
    });

    socket.on('workspace:read', async (rel: string, cb) => {
      try {
        const content = await workspace.readFile(rel);
        cb({ ok: true, content });
      } catch (e) {
        cb({ ok: false, error: (e as Error).message });
      }
    });

    socket.on('workspace:write', async (payload: { path: string; content: string }, cb) => {
      try {
        await workspace.writeFile(payload.path, payload.content);
        cb({ ok: true });
      } catch (e) {
        cb({ ok: false, error: (e as Error).message });
      }
    });

    socket.on('workspace:delete', async (rel: string, cb) => {
      try {
        await workspace.deletePath(rel);
        cb({ ok: true });
      } catch (e) {
        cb({ ok: false, error: (e as Error).message });
      }
    });

    // ---------- AI Completion (stream‚Äësimulated) ----------
    socket.on('ai:complete', async (req: { provider: AIProvider; prefix: string; suffix?: string }, cb) => {
      try {
        const result = await getCompletion(req.provider, {
          prefix: req.prefix,
          suffix: req.suffix,
          language: 'javascript',
        });
        // Simulate streaming by sending chunks every 50‚ÄØms
        const chunks = result.completion.match(/.{1,30}/g) ?? [];
        for (const ch of chunks) {
          socket.emit('ai:completionChunk', ch);
          await new Promise((r) => setTimeout(r, 50));
        }
        cb({ done: true });
      } catch (e) {
        cb({ error: (e as Error).message });
      }
    });

    // ---------- Git status (on‚Äëdemand) ----------
    socket.on('git:status', async (repoPath: string, cb) => {
      try {
        const { GitService } = await import('../git/service');
        const svc = new GitService(repoPath);
        const status = await svc.status();
        cb({ ok: true, status });
      } catch (e) {
        cb({ ok: false, error: (e as Error).message });
      }
    });

    socket.on('disconnect', () => console.log('üî¥ client disconnected', socket.id));
  });

  return io;
}
```

### `backend/src/server.ts`

```ts
import express from 'express';
import cors from 'cors';
import helmet from 'helmet';
import dotenv from 'dotenv';
import { createServer } from 'http';
import path from 'path';
import { fileURLToPath } from 'url';

import aiRoutes from './routes/ai.routes';
import gitRoutes from './routes/git.routes';
import { attachWebSocket } from './routes/ws.routes';
import { errorHandler } from './middlewares/errorHandler';
import { rateLimiter } from './middlewares/rateLimiter';

// ---------------------------------------------------------------
// Load environment variables
// ---------------------------------------------------------------
dotenv.config();

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const app = express();
const httpServer = createServer(app);

// ---------------------------------------------------------------
// Global middleware
// ---------------------------------------------------------------
app.use(cors({ origin: process.env.CLIENT_ORIGIN ?? '*' }));
app.use(helmet());
app.use(express.json({ limit: '2mb' }));
app.use(rateLimiter);

// ---------------------------------------------------------------
// API routes
// ---------------------------------------------------------------
app.use('/api/ai', aiRoutes);
app.use('/api/git', gitRoutes);

// ---------------------------------------------------------------
// Serve the built front‚Äëend (when `npm run build` was executed)
// ---------------------------------------------------------------
app.use(express.static(path.join(__dirname, '../../frontend/dist')));

// SPA fallback ‚Äì any unknown route serves index.html
app.get('*', (_req, res) => {
  res.sendFile(path.join(__dirname, '../../frontend/dist/index.html'));
});

// ---------------------------------------------------------------
// Error handling
// ---------------------------------------------------------------
app.use(errorHandler);

// ---------------------------------------------------------------
// WebSocket layer
// ---------------------------------------------------------------
attachWebSocket(httpServer);

// ---------------------------------------------------------------
// Start the server
// ---------------------------------------------------------------
const PORT = Number(process.env.PORT) || 4000;
httpServer.listen(PORT, () => console.log(`üöÄ Backend listening on http://localhost:${PORT}`));
```

---

## 3Ô∏è‚É£ Front‚Äëend ‚Äì `frontend/`

### `frontend/package.json`

```json
{
  "name": "ai-ide-frontend",
  "version": "1.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview",
    "lint": "eslint src/**/*.tsx src/**/*.ts",
    "test:e2e": "playwright test"
  },
  "dependencies": {
    "@codemirror/autocomplete": "^6.12.0",
    "@codemirror/basic-setup": "^6.4.0",
    "@codemirror/lang-javascript": "^6.2.0",
    "@codemirror/state": "^6.4.0",
    "@codemirror/view": "^6.27.0",
    "@heroicons/react": "^2.1.5",
    "@tanstack/react-query": "^5.45.0",
    "axios": "^1.7.7",
    "classnames": "^2.5.1",
    "react": "^18.3.1",
    "react-dom": "^18.3.1",
    "socket.io-client": "^4.7.5",
    "tailwind-merge": "^2.4.0"
  },
  "devDependencies": {
    "@vitejs/plugin-react": "^4.3.1",
    "autoprefixer": "^10.4.20",
    "eslint": "^9.6.0",
    "eslint-plugin-react": "^7.35.2",
    "postcss": "^8.4.41",
    "playwright": "^1.46.1",
    "typescript": "^5.5.4",
    "vite": "^5.4.1"
  }
}
```

### `frontend/tsconfig.json`

```json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ESNext",
    "moduleResolution": "Node",
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "strict": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true
  },
  "include": ["src"]
}
```

### `frontend/vite.config.ts`

```ts
import { defineConfig } from 'vite';
import react from '@vitejs/plugin-react';
import path from 'path';

export default defineConfig({
  plugins: [react()],
  server: {
    port: 5173,
    proxy: {
      '/api': {
        target: 'http://localhost:4000',
        changeOrigin: true,
        secure: false,
      },
      '/socket.io': {
        target: 'http://localhost:4000',
        ws: true,
      },
    },
  },
  resolve: {
    alias: {
      '@': path.resolve(__dirname, 'src'),
    },
  },
});
```

### `frontend/tailwind.config.cjs`

```js
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: ['./index.html', './src/**/*.{tsx,ts,js,jsx}'],
  darkMode: 'class',
  theme: {
    extend: {
      colors: {
        primary: '#007acc',
        surface: '#1e1e1e',
        overlay: '#2d2d2d',
      },
    },
  },
  plugins: [],
};
```

### `frontend/index.html`

```html
<!DOCTYPE html>
<html lang="en" class="h-full">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI‚ÄëIDE</title>
    <script type="module" src="/src/main.tsx"></script>
  </head>
  <body class="h-full bg-surface text-gray-100">
    <div id="root" class="h-full"></div>
  </body>
</html>
```

### `frontend/src/index.css`

```css
@tailwind base;
@tailwind components;
@tailwind utilities;

/* You can add custom utilities here */
```

### `frontend/src/main.tsx`

```tsx
import React from 'react';
import ReactDOM from 'react-dom/client';
import App from './App';
import './index.css';
import { QueryClient, QueryClientProvider } from '@tanstack/react-query';

const queryClient = new QueryClient();

ReactDOM.createRoot(document.getElementById('root')!).render(
  <React.StrictMode>
    <QueryClientProvider client={queryClient}>
      <App />
    </QueryClientProvider>
  </React.StrictMode>
);
```

### `frontend/src/types.ts`

```ts
export type AIProvider = 'codestral' | 'chatgpt-oss' | 'dkimi';
```

### `frontend/src/lib/socket.ts`

```ts
import { io, Socket } from 'socket.io-client';

export const socket: Socket = io('/', {
  withCredentials: true,
  transports: ['websocket'],
});

/* Tiny helper that returns a promise for socket‚Äëack events */
socket.emitWithAck = (event: string, data: any, timeout = 5000) =>
  new Promise<any>((resolve, reject) => {
    const timer = setTimeout(() => reject(new Error('Ack timeout')), timeout);
    socket.emit(event, data, (response: any) => {
      clearTimeout(timer);
      resolve(response);
    });
  });
```

### `frontend/src/hooks/useAI.ts`

```tsx
import axios from 'axios';
import { AIProvider } from '@/types';
import { CompletionRequest, CompletionResponse, ChatRequest } from '@/types';

export function useAI() {
  const requestCompletion = async (
    payload: CompletionRequest,
    provider: AIProvider = 'codestral'
  ): Promise<CompletionResponse> => {
    const res = await axios.post<CompletionResponse>('/api/ai/completion', {
      ...payload,
      provider,
    });
    return res.data;
  };

  const chat = async (payload: ChatRequest, provider: AIProvider = 'codestral'): Promise<string> => {
    const res = await axios.post<{ reply: string }>('/api/ai/chat', {
      ...payload,
      provider,
    });
    return res.data.reply;
  };

  return { requestCompletion, chat };
}
```

### `frontend/src/hooks/useWorkspace.ts`

```tsx
import { useState, useCallback } from 'react';
import { socket } from '@/lib/socket';
import { FileNode } from '@/types';

export function useWorkspace() {
  const [currentFile, setCurrentFile] = useState<string | null>(null);
  const [tree, setTree] = useState<FileNode[]>([]);

  const refreshTree = async () => {
    const data = await socket.emitWithAck('workspace:getTree', {});
    setTree(data);
  };

  const loadFile = useCallback(async (rel: string) => {
    const resp = await socket.emitWithAck('workspace:read', rel);
    if (!resp.ok) throw new Error(resp.error);
    return resp.content as string;
  }, []);

  const saveFile = useCallback(async (rel: string, content: string) => {
    const resp = await socket.emitWithAck('workspace:write', { path: rel, content });
    if (!resp.ok) throw new Error(resp.error);
  }, []);

  const deleteFile = useCallback(async (rel: string) => {
    const resp = await socket.emitWithAck('workspace:delete', rel);
    if (!resp.ok) throw new Error(resp.error);
  }, []);

  const selectFile = (path: string) => setCurrentFile(path);

  return {
    currentFile,
    selectFile,
    tree,
    refreshTree,
    loadFile,
    saveFile,
    deleteFile,
  };
}
```

### `frontend/src/components/Layout.tsx`

```tsx
export default function Layout({ children }: { children: React.ReactNode }) {
  return (
    <div className="h-screen w-screen bg-surface text-gray-200 flex flex-col">
      {/* Header */}
      <header className="h-10 bg-surface/80 flex items-center px-4 text-sm">
        <span className="font-mono">AI‚ÄëIDE ‚Äì Codestral / ChatGPT‚ÄëOSS / dKimi</span>
      </header>

      {/* Main UI */}
      <main className="flex-1 overflow-hidden">{children}</main>
    </div>
  );
}
```

### `frontend/src/components/ProviderSelect.tsx`

```tsx
import { AIProvider } from '@/types';

interface Props {
  value: AIProvider;
  onChange: (p: AIProvider) => void;
}

export default function ProviderSelect({ value, onChange }: Props) {
  const options: AIProvider[] = ['codestral', 'chatgpt-oss', 'dkimi'];

  return (
    <select
      className="bg-surface/30 text-gray-100 rounded px-2 py-1"
      value={value}
      onChange={(e) => onChange(e.target.value as AIProvider)}
    >
      {options.map((p) => (
        <option key={p} value={p}>
          {p === 'codestral'
            ? 'Codestral (FIM)'
            : p === 'chatgpt-oss'
            ? 'ChatGPT‚ÄëOSS'
            : 'dKimi'}
        </option>
      ))}
    </select>
  );
}
```

### `frontend/src/components/Explorer.tsx`

```tsx
import { useEffect } from 'react';
import { FolderIcon, DocumentIcon, PlusIcon } from '@heroicons/react/24/outline';
import { useWorkspace } from '@/hooks/useWorkspace';
import { FileNode } from '@/types';

function TreeNode({ node, path }: { node: FileNode; path: string }) {
  const { selectFile } = useWorkspace();
  const fullPath = `${path}/${node.name}`;

  return (
    <div className="ml-4">
      <div
        className="flex items-center py-0.5 hover:bg-surface/50 cursor-pointer"
        onClick={() => node.type === 'file' && selectFile(fullPath)}
      >
        {node.type === 'directory' ? (
          <FolderIcon className="w-4 h-4 mr-1 text-primary" />
        ) : (
          <DocumentIcon className="w-4 h-4 mr-1 text-gray-400" />
        )}
        <span>{node.name}</span>
      </div>
      {node.type === 'directory' && node.children?.map((c) => (
        <TreeNode key={c.name} node={c} path={fullPath} />
      ))}
    </div>
  );
}

export default function Explorer() {
  const { tree, refreshTree, currentFile, selectFile } = useWorkspace();

  useEffect(() => {
    refreshTree();
    // live updates
    socket.on('workspace:fileChanged', refreshTree);
    socket.on('workspace:fileDeleted', refreshTree);
    return () => {
      socket.off('workspace:fileChanged', refreshTree);
      socket.off('workspace:fileDeleted', refreshTree);
    };
  }, []);

  const createFile = async () => {
    const name = prompt('New file (relative to workspace, e.g. src/app.tsx):');
    if (!name) return;
    await socket.emitWithAck('workspace:write', { path: name, content: '' });
    refreshTree();
  };

  return (
    <aside className="w-64 bg-surface text-gray-100 p-2 flex flex-col">
      <div className="flex items-center justify-between mb-2">
        <h3 className="text-sm font-semibold">üìÅ Explorer</h3>
        <button onClick={createFile} title="New file">
          <PlusIcon className="w-5 h-5 text-primary" />
        </button>
      </div>
      <div className="flex-1 overflow-y-auto">
        {tree.map((node) => (
          <TreeNode key={node.name} node={node} path="" />
        ))}
      </div>
    </aside>
  );
}
```

### `frontend/src/components/Editor.tsx`

```tsx
import { useEffect, useRef, useState, useCallback } from 'react';
import { EditorState } from '@codemirror/state';
import { EditorView, keymap } from '@codemirror/view';
import { javascript } from '@codemirror/lang-javascript';
import { defaultKeymap, indentWithTab } from '@codemirror/commands';
import { autocomplete } from '@codemirror/autocomplete';
import { useAI } from '@/hooks/useAI';
import { useWorkspace } from '@/hooks/useWorkspace';
import { socket } from '@/lib/socket';
import { CompletionRequest } from '@/types';

export default function Editor() {
  const containerRef = useRef<HTMLDivElement>(null);
  const { currentFile, loadFile, saveFile } = useWorkspace();
  const { requestCompletion } = useAI();
  const [provider, setProvider] = useState<'codestral' | 'chatgpt-oss' | 'dkimi'>('codestral');

  // Load file content whenever the selected file changes
  const [doc, setDoc] = useState('// Select a file from the Explorer');

  useEffect(() => {
    if (!currentFile) return;
    loadFile(currentFile).then((content) => setDoc(content ?? ''));
  }, [currentFile, loadFile]);

  // Initialise CodeMirror once
  useEffect(() => {
    if (!containerRef.current) return;
    const startState = EditorState.create({
      doc,
      extensions: [
        javascript(),
        keymap.of([...defaultKeymap, indentWithTab]),
        autocomplete({
          override: [
            async (context) => {
              const prefix = context.state.doc.sliceString(0, context.pos);
              const suffix = context.state.doc.sliceString(context.pos);
              const result = await requestCompletion(
                {
                  prefix,
                  suffix,
                  language: 'javascript',
                } as CompletionRequest,
                provider
              );
              return {
                from: context.pos,
                options: [{ label: result.completion, apply: result.completion }],
              };
            },
          ],
        }),
        EditorView.updateListener.of((v) => {
          if (v.docChanged) {
            const newDoc = v.state.doc.toString();
            setDoc(newDoc);
            // debounce save after 1‚ÄØs
            if (currentFile) debounceSave(currentFile, newDoc);
          }
        }),
      ],
    });

    const view = new EditorView({
      state: startState,
      parent: containerRef.current,
    });

    return () => view.destroy();
  }, [containerRef, provider]);

  // Debounced auto‚Äësave
  const debounceSave = (() => {
    let timer: NodeJS.Timeout;
    return (path: string, content: string) => {
      clearTimeout(timer);
      timer = setTimeout(() => saveFile(path, content), 1000);
    };
  })();

  return (
    <div className="flex-1 overflow-hidden">
      <div className="h-full" ref={containerRef} />
    </div>
  );
}
```

### `frontend/src/components/GitPanel.tsx`

```tsx
import { useState } from 'react';
import { socket } from '@/lib/socket';
import { ArrowDownTrayIcon, ArrowUpTrayIcon, RefreshIcon } from '@heroicons/react/24/outline';

export default function GitPanel() {
  const [status, setStatus] = useState<any>(null);
  const repoPath = '/workspace';

  const fetchStatus = async () => {
    socket.emit('git:status', repoPath, (resp: any) => {
      if (resp.ok) setStatus(resp.status);
    });
  };

  const pull = async () => {
    socket.emit('git:pull', { path: repoPath, remote: 'origin', branch: 'main' }, fetchStatus);
  };

  const push = async () => {
    socket.emit('git:push', { path: repoPath, remote: 'origin', branch: 'main' }, fetchStatus);
  };

  return (
    <div className="h-48 bg-overlay text-gray-200 p-2 flex flex-col">
      <div className="flex items-center justify-between mb-2">
        <h4 className="text-sm font-medium">üõ†Ô∏è Git</h4>
        <button onClick={fetchStatus} title="Refresh">
          <RefreshIcon className="w-5 h-5" />
        </button>
      </div>

      <pre className="flex-1 overflow-y-auto text-xs whitespace-pre-wrap">
        {status ? JSON.stringify(status, null, 2) : 'Press ‚ü≥ to load status'}
      </pre>

      <div className="flex gap-2 mt-2">
        <button
          className="flex-1 bg-primary text-white py-1 rounded hover:bg-primary/80 flex items-center justify-center"
          onClick={pull}
        >
          <ArrowDownTrayIcon className="w-4 h-4 mr-1" />
          Pull
        </button>
        <button
          className="flex-1 bg-primary text-white py-1 rounded hover:bg-primary/80 flex items-center justify-center"
          onClick={push}
        >
          <ArrowUpTrayIcon className="w-4 h-4 mr-1" />
          Push
        </button>
      </div>
    </div>
  );
}
```

### `frontend/src/components/Chat.tsx`

```tsx
import { useState, useRef, useEffect } from 'react';
import { useAI } from '@/hooks/useAI';
import { PaperAirplaneIcon } from '@heroicons/react/24/outline';
import ProviderSelect from './ProviderSelect';
import { AIProvider } from '@/types';

interface Message {
  role: 'user' | 'assistant';
  content: string;
}

export default function Chat() {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [provider, setProvider] = useState<AIProvider>('chatgpt-oss'); // default for chat
  const { chat } = useAI();
  const bottomRef = useRef<HTMLDivElement>(null);

  const send = async () => {
    if (!input.trim()) return;
    const user: Message = { role: 'user', content: input };
    setMessages((m) => [...m, user]);
    setInput('');

    const reply = await chat(
      {
        messages: [{ role: 'user', content: input }],
      },
      provider
    );
    const ai: Message = { role: 'assistant', content: reply };
    setMessages((m) => [...m, ai]);
  };

  useEffect(() => {
    bottomRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  return (
    <aside className="w-80 bg-overlay text-gray-100 flex flex-col">
      <div className="p-2 flex items-center gap-2 border-b border-surface/50">
        <span className="font-medium">ü§ñ Model:</span>
        <ProviderSelect value={provider} onChange={setProvider} />
      </div>

      <div className="flex-1 overflow-y-auto p-3 space-y-3">
        {messages.map((msg, i) => (
          <div key={i} className={`flex ${msg.role === 'user' ? 'justify-end' : 'justify-start'}`}>
            <div
              className={`max-w-xs p-2 rounded ${
                msg.role === 'user' ? 'bg-primary text-white' : 'bg-surface/70'
              }`}
            >
              {msg.content}
            </div>
          </div>
        ))}
        <div ref={bottomRef} />
      </div>

      <div className="p-2 flex">
        <input
          className="flex-1 bg-surface/30 text-gray-100 rounded-l px-2 py-1 focus:outline-none"
          placeholder="Ask the model‚Ä¶"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          onKeyDown={(e) => e.key === 'Enter' && send()}
        />
        <button
          className="bg-primary text-white rounded-r px-3 flex items-center"
          onClick={send}
        >
          <PaperAirplaneIcon className="w-5 h-5 transform rotate-90" />
        </button>
      </div>
    </aside>
  );
}
```

### `frontend/src/App.tsx`

```tsx
import { useEffect, useState } from 'react';
import Layout from '@/components/Layout';
import Explorer from '@/components/Explorer';
import Editor from '@/components/Editor';
import GitPanel from '@/components/GitPanel';
import Chat from '@/components/Chat';
import { socket } from '@/lib/socket';

export default function App() {
  const [connected, setConnected] = useState(false);

  useEffect(() => {
    socket.on('connect', () => setConnected(true));
    socket.on('disconnect', () => setConnected(false));
    return () => {
      socket.off('connect');
      socket.off('disconnect');
    };
  }, []);

  return (
    <Layout>
      <div className="flex h-full">
        <Explorer />
        <div className="flex flex-col flex-1 overflow-hidden">
          <Editor />
          <GitPanel />
        </div>
        <Chat />
      </div>

      {!connected && (
        <div className="fixed bottom-0 left-0 right-0 bg-red-600 text-white text-center py-1">
          Disconnected from server ‚Äì reconnecting‚Ä¶
        </div>
      )}
    </Layout>
  );
}
```

---

## 4Ô∏è‚É£ CI ‚Äì GitHub Actions (`.github/workflows/ci.yml`)

```yaml
name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  backend:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: backend
    env:
      HF_TOKEN: ${{ secrets.HF_TOKEN }}   # read‚Äëonly token for tests
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '22'
      - run: npm ci
      - run: npm run lint
      - run: npm test

  frontend:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: frontend
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '22'
      - run: npm ci
      - run: npm run lint
      - run: npm run build
      - name: Install Playwright browsers
        run: npx playwright install
      - run: npm run test:e2e

  docker:
    needs: [backend, frontend]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DH_USERNAME }}
          password: ${{ secrets.DH_TOKEN }}
      - name: Build & push images
        run: |
          docker compose -f docker-compose.yml build
          docker compose -f docker-compose.yml push
```

Add the following **GitHub secrets** to the repository:

| Secret          | Value                                    |
|-----------------|------------------------------------------|
| `HF_TOKEN`      | Your Hugging‚ÄØFace inference token        |
| `DH_USERNAME`   | Docker Hub username                      |
| `DH_TOKEN`      | Docker Hub access token (or password)    |

---

## ‚úÖ How to Run the Whole Stack Locally

```bash
# 1Ô∏è‚É£ Clone the repo (or copy the files into a folder named ai-ide)
git clone <repo‚Äëurl> ai-ide
cd ai-ide

# 2Ô∏è‚É£ Create the .env file (copy the example above and fill in your keys)
cp .env.example .env   # then edit .env

# 3Ô∏è‚É£ Build and start everything
docker compose up --build -d

# 4Ô∏è‚É£ Open the IDE
open http://localhost:5173   # macOS
# or just point your browser to http://localhost:5173
```

### Quick sanity‚Äëcheck

* In the **Explorer** create a file `src/hello.ts`.
* Type a few lines of code, then press **Ctrl‚ÄëSpace** ‚Äì you‚Äôll see a completion generated by the **currently selected model** (default is `codestral` for the editor, `chatgpt-oss` for the chat sidebar).
* Switch the dropdown to **dKimi** and ask a Korean question in the chat ‚Äì you should receive a Korean reply.

---

## üóíÔ∏è What to Do Next (Ideas)

1. **Add a streaming endpoint** ‚Äì replace the simulated chunking in `ws.routes.ts` with real Server‚ÄëSent Events from the Hugging‚ÄØFace ‚Äústream‚Äù mode (available on paid tiers).
2. **Persist workspace in a cloud bucket** ‚Äì mount an S3‚Äëcompatible volume instead of a local `./workspace` directory.
3. **Add more language servers** (e.g., `pyright` for Python) and expose them via a new `/api/lsp` route.
4. **Enable user authentication** ‚Äì JWT + socket.io auth middleware.
5. **Add a ‚ÄúDeploy to Vercel/Netlify‚Äù button** that packages the current workspace as a static site.

---

## üéâ You‚Äôre good to go!

You now have a **full, production‚Äëready** AI‚ÄëIDE that can:

* **Generate code completions** with Codestral (FIM) **or** any Hugging‚ÄØFace chat model you prefer.
* **Chat** with the same models, picking the language‚Äëappropriate one (e.g., dKimi for Korean).
* **Manage files** and **git** without leaving the browser.
* **Run everywhere** ‚Äì locally with Docker, or in any cloud that can run Docker Compose.

Feel free to fork, extend, or ship it as part of a larger product. If you hit any snags or want to add another model, just let me know ‚Äì I‚Äôm happy to help you tweak the code further! üöÄ